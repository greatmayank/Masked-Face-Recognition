{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "\n",
    "class Classification():\n",
    "\tdef __init__(self,para_dict):\n",
    "\t\ttrain_img_dir = para_dict['train_img_dir']\n",
    "\t\ttest_img_dir = para_dict['test_img_dir']\n",
    "\t\tlabel_dict = para_dict['label_dict']\n",
    "\n",
    "\t\tif label_dict is None:\n",
    "\t\t\tlabel_dict = self.__get_label_dict(train_img_dir)\n",
    "\t\t\tprint(label_dict)\n",
    "\n",
    "\t\tclass_num = len(label_dict.keys())\n",
    "\n",
    "\t\ttrain_paths, train_labels = self.__get_paths_labels(train_img_dir,label_dict)\n",
    "\t\tprint(\"train path shape:{}, train label shape : {}\",format(train_paths.shape,train_labels.shape))\n",
    "\n",
    "\t\tif test_img_dir is not None:\n",
    "\t\t\ttest_paths, test_labels = self.__get_paths_labels(test_img_dir,label_dict)\n",
    "\t\t\tprint(\"test path shape : {}, test label shape {}\",format(test_paths.shape,test_labels.shape))\n",
    "\n",
    "\t\tself.train_img_dir = train_img_dir\n",
    "\t\tself.label_dict = label_dict\n",
    "\t\tself.train_paths = train_paths\n",
    "\t\tself.train_labels = train_labels\n",
    "\t\tself.class_num = class_num\n",
    "\t\tif test_img_dir is not None:\n",
    "\t\t\tself.test_img_dir = test_img_dir\n",
    "\t\t\tself.test_paths = test_paths\n",
    "\t\t\tself.test_labels = test_labels\n",
    "\n",
    "\n",
    "\tdef model_init(self,para_dict):\n",
    "\t\tmodel_shape = para_dict['model_shape']\n",
    "\t\tinfer_method = para_dict['infer_method']\n",
    "\t\tloss_method = para_dict['loss_method']\n",
    "\t\topti_method = para_dict['opti_method']\n",
    "\t\tlearning_rate = para_dict['learning_rate']\n",
    "\t\tsave_dir = para_dict['save_dir']\n",
    "\n",
    "\t\ttf_input = tf.placeholder(shape=model_shape,dtype=tf.float32,name='input')\n",
    "\t\ttf_keep_prob = tf.placeholder(dtype=np.float32,name=\"keep_prob\")\n",
    "\t\ttf_label_batch = tf.placeholder(shape=[None],dtype=tf.int32,name=\"label_batch\")\n",
    "\n",
    "\n",
    "\t\tif infer_method == \"simple_resnet\":\n",
    "\t\t\toutput = self.simple_resnet(tf_input,tf_keep_prob,self.class_num)\n",
    "\n",
    "\n",
    "\t\tif loss_method == \"cross_entropy\":\n",
    "\t\t\tprediction = tf.nn.softmax(output,name=\"prediction\")\n",
    "\t\t\tloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf_label_batch,logits=output),\n",
    "\t\t\t\t\t\t\t\t\tname=\"loss\")\n",
    "\n",
    "\n",
    "\t\tif opti_method == \"adam\":\n",
    "\t\t\toptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "\t\tif not os.path.exists(save_dir):\n",
    "\t\t\tos.makedirs(save_dir)\n",
    "\n",
    "\t\tout_dir_prefix = os.path.join(save_dir,\"model\")\n",
    "\t\tsaver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "\t\tpb_save_path = os.path.join(save_dir,\"pb_model.pb\")\n",
    "\t\tpb_save_list = ['prediction']\n",
    "\n",
    "\t\tlog_path = os.path.join(save_dir,\"train_result.json\")\n",
    "\t\tcontent = {\"train_img_dir\":self.train_img_dir, \"test_img_dir\":self.test_img_dir,\"label_dict\":label_dict}\n",
    "\n",
    "\t\tself.tf_input = tf_input\n",
    "\t\tself.tf_keep_prob = tf_keep_prob\n",
    "\t\tself.tf_label_batch = tf_label_batch\n",
    "\t\tself.optimizer = optimizer\n",
    "\t\tself.prediction = prediction\n",
    "\t\tself.out_dir_prefix = out_dir_prefix\n",
    "\t\tself.saver = saver\n",
    "\t\tself.pb_save_list = pb_save_list\n",
    "\t\tself.pb_save_path = pb_save_path\n",
    "\t\tself.log_path = log_path\n",
    "\t\tself.content = content\n",
    "\t\tself.save_dir = save_dir\n",
    "\t\tself.model_shape = model_shape\n",
    "\t\tself.loss = loss\n",
    "\n",
    "\n",
    "\tdef train(self,para_dict):\n",
    "\t\tepochs = para_dict['epochs']\n",
    "\t\tGPU_ratio = para_dict['GPU_ratio']\n",
    "\t\tbatch_size = para_dict['batch_size']\n",
    "\n",
    "\t\ttrain_ites = math.ceil(self.train_paths.shape[0] / batch_size)\n",
    "\n",
    "\t\tif self.test_img_dir is not None:\n",
    "\t\t\ttest_ites =  math.ceil(self.test_paths.shape[0] / batch_size)\n",
    "\n",
    "\t\tconfig = tf.ConfigProto(log_device_placement=True,allow_soft_placement=True)\n",
    "\t\t\n",
    "\t\tif GPU_ratio is None:\n",
    "\t\t\tconfig.gpu_options.allow_growth = True\n",
    "\t\telse:\n",
    "\t\t\tconfig.gpu_options.per_process_gpu_memory_fraction = GPU_ratio\n",
    "\n",
    "\t\twith tf.session(config=config) as sess:\n",
    "\t\t\tfiles = [file.path for file in os.scandir(self.save_dir) if file.name.split(\".\")[-1] == 'meta']\n",
    "\t\t\tif len(files)==0:\n",
    "\t\t\t\tsess.run(tf.global_variables_initializer())\n",
    "\t\t\t\tprint(\"No previous model can be used!\")\n",
    "\t\t\telse:\n",
    "\t\t\t\t#self.saver.restore(tf.train.latest_checkpoint(self.save_dir))\n",
    "\t\t\t\t#print(\"Use previous model\")\n",
    "\t\t\t\tcheck_name = files[-1].split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\t\t\t\tmodel_path = os.path.join(self.save_dir,check_name)\n",
    "\t\t\t\tself.saver.restore(model_path)\n",
    "\t\t\t\tmsg = \"use previous model param {}\".format(model_path)\n",
    "\t\t\t\tprint(msg)\n",
    "\t\t\tfor epoch in ranges(epochs):\n",
    "\t\t\t\ttrain_loss = 0\n",
    "\t\t\t\ttrain_acc = 0\n",
    "\t\t\t\ttest_loss = 0\n",
    "\t\t\t\ttest_acc = 0\n",
    "\t\t\t\tindice = np.random.permutation(self.train_paths.shape[0])\n",
    "\t\t\t\tself.train_paths = self.train_paths[indice]\n",
    "\t\t\t\tself.train_labels = self.train_labels[indice]\n",
    "\n",
    "\t\t\t\tfor index in range(train_ites):\n",
    "\t\t\t\t\tnum_start = index * batch_size\n",
    "\t\t\t\t\tnum_end = np.minimum(num_start + batch_size, self.train_paths.shape[0])\n",
    "\n",
    "\t\t\t\t\tbatch_data = self.get_4D_data(self.train_paths[num_start:num_end],self.model_shape[1:])\n",
    "\n",
    "\t\t\t\t\tfeed_dict = {self.tf_input:batch_data,\n",
    "\t\t\t\t\t\t\t\tself.tf_label_batch:self.train_labels[num_start:num_end],\n",
    "\t\t\t\t\t\t\t\tself.tf_keep_prob:0.8}\n",
    "\n",
    "\t\t\t\t\tsess.run(self.optimizer,feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\t\t\t\tfor index in range(train_ites):\n",
    "\t\t\t\t\tnum_start = index * batch_size\n",
    "\t\t\t\t\tnum_end = np.minimum(num_start + batch_size, self.train_paths.shape[0])\n",
    "\n",
    "\t\t\t\t\tbatch_data = self.get_4D_data(self.train_paths[num_start:num_end],self.model_shape[1:])\n",
    "\n",
    "\t\t\t\t\tfeed_dict = {self.tf_input:batch_data,\n",
    "\t\t\t\t\t\t\t\tself.tf_label_batch:self.train_labels[num_start:num_end],\n",
    "\t\t\t\t\t\t\t\tself.tf_keep_prob:1.0}\n",
    "\n",
    "\t\t\t\t\tloss_temp, predict_temp = sess.run([self.loss,self.prediction],feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\t\t\t\t\ttrain_loss += loss_temp\t\n",
    "\t\t\t\t\ttrain_acc += self.evaluation(predict_temp,self.train_labels[num_start:num_end])\n",
    "\n",
    "\t\t\t\ttrain_loss /= train_ites\n",
    "\t\t\t\ttrain_acc /= self.train_paths.shape[0]\n",
    "\n",
    "\t\t\t\tprint(\"train loss : {}, train accuracy : {}\",format(train_loss,train_acc))\n",
    "\n",
    "\t\t\t\tif self.test_img_dir is not None:\n",
    "\t\t\t\t\tfor index in range(test_ites):\n",
    "\t\t\t\t\t\tnum_start = index * batch_size\n",
    "\t\t\t\t\t\tnum_end = np.minimum(num_start + batch_size, self.test_paths.shape[0])\n",
    "\n",
    "\t\t\t\t\t\tbatch_data = self.get_4D_data(self.test_paths[num_start:num_end],self.model_shape[1:])\n",
    "\n",
    "\t\t\t\t\t\tfeed_dict = {self.tf_input:batch_data,\n",
    "\t\t\t\t\t\t\t\t\tself.tf_label_batch:self.test_labels[num_start:num_end],\n",
    "\t\t\t\t\t\t\t\t\tself.tf_keep_prob:1.0}\n",
    "\n",
    "\t\t\t\t\t\tloss_temp, predict_temp = sess.run([self.loss,self.prediction],feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "\t\t\t\t\t\ttest_loss += loss_temp\t\n",
    "\t\t\t\t\t\ttest_acc += self.evaluation(predict_temp,self.test_labels[num_start:num_end])\n",
    "\n",
    "\t\t\t\t\ttest_loss /= test_ites\n",
    "\t\t\t\t\ttest_acc /= self.test_paths.shape[0]\n",
    "\n",
    "\t\t\t\t\tprint(\"test loss : {}, test accuracy : {}\",format(test_loss,test_acc))\n",
    "\n",
    "\n",
    "\tdef evaluation(self,predictions,labels):\n",
    "\t\tcount = 0\n",
    "\t\tfor i in range(predictions.shape[0]):\n",
    "\t\t\tif np.argmax(predictions[i] == labels[i]):\n",
    "\t\t\t\tcount += 1\n",
    "\n",
    "\t\treturn count\n",
    "\n",
    "\tdef get_4D_data(self,paths,img_shape):\n",
    "\t\tre_array = []\n",
    "\t\tfor path in paths:\n",
    "\t\t\timg = cv2.imread(path)\n",
    "\t\t\tif img is None:\n",
    "\t\t\t\tprint(\"read failed:\",path)\n",
    "\t\t\telse:\n",
    "\t\t\t\timg = cv2.resize(img,(img_shape[1],img_shape[0]))\n",
    "\t\t\t\timg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        \t\timg = img.astype(np.float32)\n",
    "        \t\timg /= 255\n",
    "        \t\tre_array.append(img)\n",
    "\n",
    "        re_array = np.array(re_array)\n",
    "\n",
    "        return re_array\n",
    "\n",
    "\n",
    "\tdef __get_label_dict(self,img_dir):\n",
    "\t\tlabel_dict = dict()\n",
    "\t\tcount = 0\n",
    "\n",
    "\t\tfor obj in os.scandir(img_dir):\n",
    "\t\t\tif obj.is_dir():\n",
    "\t\t\t\tlabel_dict[obj.name] = count\n",
    "\t\t\t\tcount += 1\n",
    "\n",
    "\t\tif count == 0:\n",
    "\t\t\tprint(\"No dir in the \",img_dir)\n",
    "\t\t\treturn None\n",
    "\t\telse:\n",
    "\t\t\treturn label_dict\n",
    "\n",
    "\n",
    "\tdef __get_paths_labels(self,train_img_dir,label_dict):\n",
    "\t\timg_format = {'jpg','png','bmp'}\n",
    "\t\tre_paths  = list()\n",
    "\t\tre_labels = list()\n",
    "\n",
    "\t\tdirs = [obj.path for obj in os.scandir(img_dir) if obj.is_dir()]\n",
    "\t\tif len(dirs) == 0:\n",
    "\t\t\tprint(\"No dirs in the \",img_dir)\n",
    "\t\telse:\n",
    "\t\t\tfor dir_path in dirs:\n",
    "\t\t\t\tpath_temp = [file.path for file in os.scandir(dir_path) if file.name.split(\".\")[-1] in img_format]\n",
    "\t\t\t\tif len(path_temp) == 0:\n",
    "\t\t\t\t\tprint(\"No images in the \",dir_path)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tlabel_num = dir_path.split(\"\\\\\")[-1]\n",
    "\t\t\t\t\tlabel_num = label_dict[label_num]\n",
    "\n",
    "\t\t\t\t\tlabel_temp = np.ones(len(path_temp),dtype=np.int32)*label_num\n",
    "\n",
    "\t\t\t\t\tre_paths.extend(path_temp)\n",
    "\t\t\t\t\tre_labels.extend(label_temp)\n",
    "\n",
    "\t\t\t\t\tre_paths = np.array(re_paths)\n",
    "\t\t\t\t\tre_labels = np.array(re_labels)\n",
    "\n",
    "\t\t\t\t\tindice = np.random.permutation(re_paths.shape[0])\n",
    "\t\t\t\t\tre_paths = re_paths[indice]\n",
    "\t\t\t\t\tre_labels = re_labels[indice]\n",
    "\n",
    "\t\t\t\t\treturn re_paths,re_labels\n",
    "\n",
    "\n",
    "\tdef resnet_block(self,input_x,k_size=3,filters=32):\n",
    "\t\tnet = tf.layers.conv2d(\n",
    "\t\t\tinput = input_x,\n",
    "\t\t\tfilters = filters,\n",
    "\t\t\tkernel_size = [k_size,k_size],\n",
    "\t\t\tkernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.1),\n",
    "\t\t\tpadding = \"same\",\n",
    "\t\t\tactivation = tf.nn.relu\n",
    "\t\t\t)\n",
    "\t\tnet = tf.layers.conv2d(\n",
    "\t\t\tinput = input_x,\n",
    "\t\t\tfilters = filters,\n",
    "\t\t\tkernel_size = [k_size,k_size],\n",
    "\t\t\tkernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.1),\n",
    "\t\t\tpadding = \"same\",\n",
    "\t\t\tactivation = tf.nn.relu\n",
    "\t\t\t)\n",
    "\t\tnet_1 = tf.layers.conv2d(\n",
    "\t\t\tinput = input_x,\n",
    "\t\t\tfilters = filters,\n",
    "\t\t\tkernel_size = [k_size,k_size],\n",
    "\t\t\tkernel_regularizer = tf.contrib.layers.l2_regularizer(scale=0.1),\n",
    "\t\t\tpadding = \"same\",\n",
    "\t\t\tactivation = tf.nn.relu\n",
    "\t\t\t)\n",
    "\t\tadd = tf.add(net,net_1)\n",
    "\n",
    "\t\tadd_result = tf.nn.relu(add)\n",
    "\n",
    "\t\treturn add_result\n",
    "\n",
    "\tdef simple_resnet(self,tf_input,tf_keep_prob,class_num):\n",
    "\t\tnet = self.resnet_block(tf_input,k_size=3,filters=16)\n",
    "\t\tnet = tf.layers.max_pooling2d(inputs=net,pool_size=[2,2],strides =2)\n",
    "\t\tprint(\"pool_1 shape : \",net.shape)\n",
    "\n",
    "\t\tnet = self.resnet_block(tf_input,k_size=3,filters=32)\n",
    "\t\tnet = tf.layers.max_pooling2d(inputs=net,pool_size=[2,2],strides =2)\n",
    "\t\tprint(\"pool_2 shape : \",net.shape)\n",
    "\n",
    "\t\tnet = self.resnet_block(tf_input,k_size=3,filters=48)\n",
    "\t\tnet = tf.layers.max_pooling2d(inputs=net,pool_size=[2,2],strides =2)\n",
    "\t\tprint(\"pool_3 shape : \",net.shape)\n",
    "\n",
    "\t\tnet = self.resnet_block(tf_input,k_size=3,filters=64)\n",
    "\t\tnet = tf.layers.max_pooling2d(inputs=net,pool_size=[2,2],strides =2)\n",
    "\t\tprint(\"pool_4 shape : \",net.shape)\n",
    "\n",
    "\t\tnet = tf.layers.flatten(net)\n",
    "\t\tprint(\"flatten shape :\",net.shape)\n",
    "\n",
    "\t\tnet = tf.nn.dropout(net,keep_prob=tf_keep_prob)\n",
    "\n",
    "\t\tnet = tf.layers.dense(inputs=net,units=128,activation=tf.nn.relu)\n",
    "\t\tprint(\"FC Shape:\",net.shape)\n",
    "\n",
    "\t\toutput = tf.layers.dense(inputs=net,units=class_num,activation=None)\n",
    "\t\tprint(\"output shape:\",net.shape)\n",
    "\n",
    "\t\treturn output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\ttrain_img_dir = r\"\" #Add Location of train folder in here\n",
    "\ttest_img_dir = r\"\"  #Add Location of test folder in here\n",
    "\tlabel_dict = None\n",
    "\tpara_dict = {\"train_img_dir\":train_img_dir,\"test_img_dir\":test_img_dir,\"label_dict\":label_dict}\n",
    "\tcls = Classification(para_dict)\n",
    "\n",
    "\tmodel_shape = [None,28,28,3]\n",
    "\tinfer_method = \"simple_resnet\"\n",
    "\tloss_method = \"cross_entropy\"\n",
    "\topti_method = \"adam\"\n",
    "\tlearning_rate = 1e-4\n",
    "\tsave_dir = r\"\"  #Add location of folder for saving model\n",
    "\tpara_dict = {\"model_shape\":model_shape,\"infer_method\":infer_method,\"loss_method\":loss_method,\n",
    "\t\t\t\t\"opti_method\":opti_method,\"learning_rate\":learning_rate,\"save_dir\":save_dir}\n",
    "\n",
    "\n",
    "\tcls.model_init(para_dict)\n",
    "\n",
    "\tepochs = 100\n",
    "\tGPU_ratio = None\n",
    "\tbatch_size = 32\n",
    "\tpara_dict = {\"epochs\":epochs,\"GPU_ratio\":GPU_ratio,\"batch_size\":batch_size}\n",
    "\tcls.train(para_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
